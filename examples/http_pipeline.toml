# HTTP ETL Pipeline Example (DAG Format)
# This pipeline fetches data from a public API, transforms it, and outputs to JSON

[pipeline]
name = "http_data_processing"
version = "1.0.0"
description = "Fetch JSON data from HTTP API and process it"

[global]
log_level = "info"
max_parallel_tasks = 2
timeout_seconds = 300
plugins = ["http"]  # Load HTTP plugin dynamically

# Stage 1: HTTP Source - Fetch data from JSONPlaceholder API
[[stages]]
id = "users_api"
type = "plugin.http"
inputs = []

[stages.config]
url = "https://jsonplaceholder.typicode.com/users"
method = "GET"
format = "json"
timeout = 30

# Stage 2: Validate schema
[[stages]]
id = "validate_data"
function = "validate.schema"
inputs = ["users_api"]

[stages.config]
required_fields = ["id", "name", "email"]
non_nullable = ["id", "name"]

# Stage 3: Output to JSON file
[[stages]]
id = "output_json"
function = "json.write"
inputs = ["validate_data"]

[stages.config]
path = "output/http_users.json"
format = "records"
pretty = true

# Stage 4: Also output to stdout for preview (branching)
[[stages]]
id = "preview"
function = "stdout.write"
inputs = ["validate_data"]

[stages.config]
format = "table"
limit = 5

# Error Handling
[error_handling]
strategy = "continue"
max_retries = 3
retry_delay_seconds = 5

[error_handling.dead_letter_queue]
enabled = true
path = "errors/http_errors/"
